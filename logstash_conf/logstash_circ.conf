input {

        beats {
                type => beats
                port => 5044
        }

        exec {
                        type => "usage"
                        command => "sar 1 1 | grep Average | xargs"
                        interval => 59
        }

        exec {
                        type => "paging"
                        command => "sar -B 1 1 | grep Average | xargs"
                        interval => 59
        }

        exec {
                        type => "memory"
                        command => "sar -r 1 1 | grep Average | xargs"
                        interval => 59
        }

        exec {
                        type => "load"
                        command => "sar -q 1 1 | grep Average | xargs"
                        interval => 59
        }

        exec {
                        type => "netstat"
                        command => "sar -n DEV 1 1 | grep Average | grep eth0 | xargs"
                        interval => 59
        }


}
filter {
        if [type] == "usage"{
                grok {
                         match => { "message" => "Average: all %{NUMBER:user:float} %{NUMBER:nice:float} %{NUMBER:system:float} %{NUMBER:iowait:float} %{NUMBER:steal:float} %{NUMBER:idle:float}" }
                }
        }
        else if [type] == "paging"{
                grok {
                        match => { "message" => "Average: %{NUMBER:pgpgin:float} %{NUMBER:pgpgout:float} %{NUMBER:fault:float} %{NUMBER:majflt:float}" }
                }
        }
        else if [type] == "memory"{
                grok {
                        match => { "message" => "Average: %{NUMBER:kbmemfre:float} %{NUMBER:kbmemused:float} %{NUMBER:memused:float} %{NUMBER:kbbuffers:float} %{NUMBER:kbcached:float} %{NUMBER:kbcommit:float} %{NUMBER:commit:float}" }
                }
        }

        else if [type] == "load"{
                grok {
                match => { "message" => "Average: %{NUMBER:runq_sz:int} %{NUMBER:plist_sz:int} %{NUMBER:ldavg_1:float} %{NUMBER:ldavg_5:float} %{NUMBER:ldavg_15:float}"}
                }
        }

       else if [type] == "netstat"{
                grok {
                        match => { "message" => "Average: %{WORD:iface} %{NUMBER:rxpck_s:float} %{NUMBER:txpck_s:float} %{NUMBER:rxkB_s:float} %{NUMBER:txkB_s:float} %{NUMBER:rxcmp_s:float} %{NUMBER:txcmp_s:float} %{NUMBER:rxmcst_s:float}"}
                }
        }
                else if [type] == "gc_logs"{
                                grok {
                                    patterns_dir => ["/home/ec2-user/stash_config/patterns"]
                                                match => { "message" => "%{DATE:date}%{DATA}%{SIZE:NewGenBeforeMinorGC:int}%{DATA}%{SIZE_2:NewGenSizeAfterMinorGC:int}%{DATA}%{SPACE}%{GC_TIME:NewGenGCTime:float}%{TIME_SUFFIX}%{NOTADIGIT}%{NOT_IMPORTANT_2}%{SIZE_3:OldGenBeforeGC:int}%{SUFFIX_OR_TIME}%{SIZE_4:OldGenAfterGC:int}%{SIZE_5}%{TIME:OldGenGCTime:float}%{SUFFIX_3}"}
                                }
                }
        else {

                multiline {
                                pattern => "^(?!^\[).*$|(^.+Exception: .+)|(^\s+at .+)|(^\s+... \d+ more)|(^\s*Caused by:.+)"
                                what => "previous"
                        }
                grok {
                        match => ["message" ,  "\[%{DATA:datestamp}\]%{SPACE}%{NOTSPACE:class}%{SPACE}%{LOGLEVEL:logLevel}%{SPACE}%{IP:ipv6}:%{POSINT:port} %{DATA:method} %{URIPATHPARAM:url} %{DATA:url_params} %{WORD:httpVersion} %{NUMBER:code} %{NUMBER:bytes:int} %{NUMBER:responseTime:int} %{GREEDYDATA:Message}",
                                "message" ,  "\[%{DATA:datestamp}\]%{SPACE}%{NOTSPACE:thread}%{SPACE}%{LOGLEVEL:logLevel}%{SPACE}%{GREEDYDATA:Message}"
                        ]
                }
                #grok parsing should fail on auditing only hopefully
                if "_grokparsefailure" in [tags] {
                        json{
                                source => "message"
                                #add tag if parsing succeeds
                                add_tag => [ "audit" ]
                        }
                        #push milli timestamp from $ts to the @timestamp field
                        date {
                                match => ["ts.$ts", UNIX]
                        }
                        mutate {
                        # Rename
                         rename => { "o2" => "updated_id" }
                        }
                        mutate {
                        # Rename
                                rename => { "ns" => "collection" }
                        }
                        #keep only these fields - needs plugin installed - logstash-plugin install logstash-filter-prune
                        prune {
                                whitelist_names => ["@timestamp","collection","op", "updated_id", "o"]
                        }
                }

        }
}

output {
  elasticsearch {
        hosts => ["ec2-52-41-57-165.us-west-2.compute.amazonaws.com:9200"]
  }
  stdout {
        codec => rubydebug
  }
}
